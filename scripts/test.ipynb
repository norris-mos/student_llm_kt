{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append('/mnt/ceph_rbd/LoRa/student_llm_kt/src')\n",
    "sys.path.append('/mnt/ceph_rbd/LoRa/student_llm_kt/src/DKT_src')\n",
    "from training import train_dynamic_kt\n",
    "from LoRa_preprocessing import StudentInteractionsDataset, DataFrame2InteractionDictionary,load_data\n",
    "from dataloader_new import SequenceDataset, options_dataloader_preproc_process\n",
    "answers,questions,misconceptions,question_subject = load_data('/mnt/ceph_rbd/LoRa/data')\n",
    "from torch.utils.data import DataLoader\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = DataFrame2InteractionDictionary(answers,questions,misconceptions,question_subject,train_split=0.9)\n",
    "data.createedi(3456784,'/mnt/ceph_rbd/LoRa/filtered_interaction_dictionaries/eedi_train0.9.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.train_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = SequenceDataset(data.train_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Create dataloaders\n",
    "train_loader = DataLoader(\n",
    "    SequenceDataset(data.train_dictionary),\n",
    "    batch_size=9,\n",
    "    shuffle=True,\n",
    "    collate_fn=options_dataloader_preproc_process,\n",
    "    num_workers=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_batch = next(iter(train_loader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = data.train_dictionary\n",
    "\n",
    "first_10_dict = {k: test[k] for k in list(test.keys())[:len(list(test.keys()))*0.1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data loaders\n",
    "train_loader = DataLoader(\n",
    "    SequenceDataset(test), \n",
    "    batch_size=5, \n",
    "    drop_last=True, \n",
    "    shuffle=True, \n",
    "    collate_fn=options_dataloader_preproc_process, \n",
    "    num_workers=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_batch = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_batch['question_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_batch['QuestionEmbedding'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_config = {\n",
    "    'question_id': {\n",
    "        'type': 'embedding',\n",
    "        'num_embeddings': 10000,\n",
    "        'embedding_dim': 64\n",
    "    },\n",
    "    'options': {\n",
    "        'type': 'embedding',\n",
    "        'num_embeddings': 4,\n",
    "        'embedding_dim': 23\n",
    "    },\n",
    "    'misconceptions': {\n",
    "        'type': 'embedding_with_mask',\n",
    "        'num_embeddings': 100000,\n",
    "        'embedding_dim': 65,\n",
    "        'input_key': 'misconceptions',\n",
    "        'mask_key': 'misconception_mask'\n",
    "    }\n",
    "}\n",
    "\n",
    "model_config = {\n",
    "    'hidden_dim': 256,\n",
    "    'nhead': 2,\n",
    "    'num_layers': 1,\n",
    "    'dropout': 0.1\n",
    "}\n",
    "\n",
    "training_config = {\n",
    "    'batch_size': 32,\n",
    "    'max_epochs': 100,\n",
    "    'patience': 10,\n",
    "    'learning_rate': 0.001,\n",
    "    'save_model': True,\n",
    "    'save_dir': 'models/',\n",
    "    'num_workers': 4\n",
    "}\n",
    "\n",
    "best_model_state, best_metrics = train_dynamic_kt(\n",
    "    train_data=train_loader,\n",
    "    val_data=train_loader,\n",
    "    feature_config=feature_config,\n",
    "    model_config=model_config,\n",
    "    training_config=training_config,\n",
    "    experiment_name=\"DKT_experiment\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unsloth_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
