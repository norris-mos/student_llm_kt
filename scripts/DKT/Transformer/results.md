




# /mnt/ceph_rbd/LoRa/student_llm_kt/scripts/DKT/Transformer/models/dict_keys(['question_ids', 'selected_options', 'correct_options', 'time_steps'])_best.pt
Test Set Metrics:
loss: 1.1189973902551842
accuracy: 0.5012035840583579
f1_micro: 0.5012035840583579
f1_macro: 0.49990211340422375
precision_per_class: [0.50801923 0.46487415 0.5044956  0.5353716 ]
recall_per_class: [0.54586419 0.52062468 0.44108085 0.48968831]
f1_per_class: [0.52626221 0.49117248 0.47066178 0.51151198]

#/mnt/ceph_rbd/LoRa/student_llm_kt/scripts/DKT/Transformer/models/dict_keys(['question_ids', 'selected_options', 'QuestionEmbedding', 'correct_options', 'time_steps'])_best.pt

wandb: WARNING Saving files without folders. If you want to preserve subdirectories pass base_path to wandb.save, i.e. wandb.save("/mnt/folder/file.h5", base_path="/mnt")
wandb:                                                                                
wandb: 
wandb: Run history:
wandb: best_val_accuracy ▁
wandb: best_val_f1_macro ▁
wandb: best_val_f1_micro ▁
wandb:             epoch ▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██
wandb:        train_loss █▅▄▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁
wandb:      val_accuracy ▁▃▄▄▆▅▇▆▆▆▇▆▇▇▇███▇▇
wandb:      val_f1_macro ▁▃▄▅▇▅▇▆▆▆▇▇▇▇▇███▇▇
wandb:      val_f1_micro ▁▃▄▄▆▅▇▆▆▆▇▆▇▇▇███▇▇
wandb:          val_loss █▆▅▅▃▃▂▂▃▂▂▂▂▂▂▁▁▂▂▁
wandb: 
wandb: Run summary:
wandb: best_val_accuracy 0.52336
wandb: best_val_f1_macro 0.52193
wandb: best_val_f1_micro 0.52336
wandb:             epoch 19
wandb:        train_loss 1.10042
wandb:      val_accuracy 0.51563
wandb:      val_f1_macro 0.51512
wandb:      val_f1_micro 0.51563
wandb:          val_loss 1.10969
wandb: 
wandb: 🚀 View run DKT_experiment at: https://wandb.ai/pixel-mamba/Dynamic_KT/runs/ukz86fxy
wandb: ⭐️ View project at: https://wandb.ai/pixel-mamba/Dynamic_KT
wandb: Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_205717-ukz86fxy/logs
35460
                                                                                                                                                
Test Set Metrics:
loss: 1.0816093289819895
accuracy: 0.5229121930900023
f1_micro: 0.5229121930900023
f1_macro: 0.5218812259372259
precision_per_class: [0.52777718 0.4954155  0.51838217 0.5534474 ]
recall_per_class: [0.56986682 0.52067167 0.48271246 0.51190887]
f1_per_class: [0.54801503 0.5077297  0.49991185 0.53186833]